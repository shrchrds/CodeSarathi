{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send a GET request to the website and get the HTML response\n",
    "url = \"https://ollama.com/blog/gemma2\"\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Google Gemma 2'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"h1\")[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the articles on the page\n",
    "articles = soup.find_all([\"h1\", \"h2\", \"p\", \"pre\", \"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h1 class=\"text-4xl font-semibold tracking-tight\">Google Gemma 2</h1>,\n",
       " <h2 class=\"text-neutral-500\">June 27, 2024</h2>,\n",
       " <p><img alt=\"Ollama in Noogler hat with Gemma 2 logo\" src=\"/public/blog/gemma2.png\"/></p>,\n",
       " <p>Note: this model requires Ollama 0.1.47 or later. <a href=\"https://ollama.com/download\">Download Ollama here</a>.</p>,\n",
       " <p>Google Gemma 2 is now available in two sizes, 9B and 27B, featuring a brand new architecture designed for class leading performance and efficiency.</p>,\n",
       " <p><strong>To run Gemma 2:</strong></p>,\n",
       " <pre><code>ollama run gemma2\n",
       " </code></pre>,\n",
       " <h2>Class leading performance</h2>,\n",
       " <p>At 27 billion parameters, Gemma 2 delivers performance surpassing models more than twice its size in benchmarks. This breakthrough efficiency sets a new standard in the open model landscape.</p>,\n",
       " <h2>Two sizes: 9B and 27B parameters</h2>,\n",
       " <p>The initial release of Gemma 2 includes two sizes:</p>,\n",
       " <h2>Using Gemma 2 with popular tooling</h2>,\n",
       " <pre><code class=\"language-python\">from langchain_community.llms import Ollama\n",
       " llm = Ollama(model=\"gemma2\")\n",
       " llm.invoke(\"Why is the sky blue?\")\n",
       " </code></pre>,\n",
       " <pre><code class=\"language-python\">from llama_index.llms.ollama import Ollama\n",
       " llm = Ollama(model=\"gemma2\")\n",
       " llm.complete(\"Why is the sky blue?\")\n",
       " </code></pre>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"gemma2.txt\", \"a\") as f:  # Open the file in append mode\n",
    "    all_text = \"\"\n",
    "    for article in articles:\n",
    "        all_text += article.text\n",
    "        f.write(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Gemma 2Google Gemma 2June 27, 2024Google Gemma 2June 27, 2024Google Gemma 2June 27, 2024Note: this model requires Ollama 0.1.47 or later. Download Ollama here.Google Gemma 2June 27, 2024Note: this model requires Ollama 0.1.47 or later. Download Ollama here.Google Gemma 2 is now available in two sizes, 9B and 27B, featuring a brand new architecture designed for class leading performance and efficiency.Google Gemma 2June 27, 2024Note: this model requires Ollama 0.1.47 or later. Download Ollama here.Google Gemma 2 is now available in two sizes, 9B and 27B, featuring a brand new architecture designed for class leading performance and efficiency.To run Gemma 2:Google Gemma 2June 27, 2024Note: this model requires Ollama 0.1.47 or later. Download Ollama here.Google Gemma 2 is now available in two sizes, 9B and 27B, featuring a brand new architecture designed for class leading performance and efficiency.To run Gemma 2:ollama run gemma2\n",
      "Google Gemma 2June 27, 2024Note: this model requires Ollama 0.1.47 or later. Download Ollama here.Google Gemma 2 is now available in two sizes, 9B and 27B, featuring a brand new architecture designed for class leading performance and efficiency.To run Gemma 2:ollama run gemma2\n",
      "Class leading performanceGoogle Gemma 2June 27, 2024Note: this model requires Ollama 0.1.47 or later. Download Ollama here.Google Gemma 2 is now available in two sizes, 9B and 27B, featuring a brand new architecture designed for class leading performance and efficiency.To run Gemma 2:ollama run gemma2\n",
      "Class leading performanceAt 27 billion parameters, Gemma 2 delivers performance surpassing models more than twice its size in benchmarks. This breakthrough efficiency sets a new standard in the open model landscape.Google Gemma 2June 27, 2024Note: this model requires Ollama 0.1.47 or later. Download Ollama here.Google Gemma 2 is now available in two sizes, 9B and 27B, featuring a brand new architecture designed for class leading performance and efficiency.To run Gemma 2:ollama run gemma2\n",
      "Class leading performanceAt 27 billion parameters, Gemma 2 delivers performance surpassing models more than twice its size in benchmarks. This breakthrough efficiency sets a new standard in the open model landscape.Two sizes: 9B and 27B parametersGoogle Gemma 2June 27, 2024Note: this model requires Ollama 0.1.47 or later. Download Ollama here.Google Gemma 2 is now available in two sizes, 9B and 27B, featuring a brand new architecture designed for class leading performance and efficiency.To run Gemma 2:ollama run gemma2\n",
      "Class leading performanceAt 27 billion parameters, Gemma 2 delivers performance surpassing models more than twice its size in benchmarks. This breakthrough efficiency sets a new standard in the open model landscape.Two sizes: 9B and 27B parametersThe initial release of Gemma 2 includes two sizes:Google Gemma 2June 27, 2024Note: this model requires Ollama 0.1.47 or later. Download Ollama here.Google Gemma 2 is now available in two sizes, 9B and 27B, featuring a brand new architecture designed for class leading performance and efficiency.To run Gemma 2:ollama run gemma2\n",
      "Class leading performanceAt 27 billion parameters, Gemma 2 delivers performance surpassing models more than twice its size in benchmarks. This breakthrough efficiency sets a new standard in the open model landscape.Two sizes: 9B and 27B parametersThe initial release of Gemma 2 includes two sizes:Using Gemma 2 with popular toolingGoogle Gemma 2June 27, 2024Note: this model requires Ollama 0.1.47 or later. Download Ollama here.Google Gemma 2 is now available in two sizes, 9B and 27B, featuring a brand new architecture designed for class leading performance and efficiency.To run Gemma 2:ollama run gemma2\n",
      "Class leading performanceAt 27 billion parameters, Gemma 2 delivers performance surpassing models more than twice its size in benchmarks. This breakthrough efficiency sets a new standard in the open model landscape.Two sizes: 9B and 27B parametersThe initial release of Gemma 2 includes two sizes:Using Gemma 2 with popular toolingfrom langchain_community.llms import Ollama\n",
      "llm = Ollama(model=\"gemma2\")\n",
      "llm.invoke(\"Why is the sky blue?\")\n",
      "Google Gemma 2June 27, 2024Note: this model requires Ollama 0.1.47 or later. Download Ollama here.Google Gemma 2 is now available in two sizes, 9B and 27B, featuring a brand new architecture designed for class leading performance and efficiency.To run Gemma 2:ollama run gemma2\n",
      "Class leading performanceAt 27 billion parameters, Gemma 2 delivers performance surpassing models more than twice its size in benchmarks. This breakthrough efficiency sets a new standard in the open model landscape.Two sizes: 9B and 27B parametersThe initial release of Gemma 2 includes two sizes:Using Gemma 2 with popular toolingfrom langchain_community.llms import Ollama\n",
      "llm = Ollama(model=\"gemma2\")\n",
      "llm.invoke(\"Why is the sky blue?\")\n",
      "from llama_index.llms.ollama import Ollama\n",
      "llm = Ollama(model=\"gemma2\")\n",
      "llm.complete(\"Why is the sky blue?\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"gemma2.txt\", \"r\") as f:\n",
    "    content = f.read()\n",
    "    print(content) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
